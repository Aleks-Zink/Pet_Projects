{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поиск гиперпараметров для каждой сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нахождение наилучших гиперпараметров для CNN, LSTM, LSTM_CNN моделей для текстов полученных при помощи Word2Vec и FastText."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы с архитектурами нейронных сетей и данные для обучения и теста взяты из файла *dataset_and_models.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Расчёты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from dataset_and_models import VECTOR_SIZE\n",
    "from dataset_and_models import CNN, LSTM, LSTM_CNN\n",
    "from dataset_and_models import w2v_data_train, w2v_data_test\n",
    "from dataset_and_models import fasttext_data_train, fasttext_data_test\n",
    "from sklearn.metrics import f1_score\n",
    "from hyperopt import fmin, tpe, hp, space_eval\n",
    "from functools import partial\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# установка устройва для расчётов\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(\n",
    "        parametterization,\n",
    "        model_class, \n",
    "        data_train,\n",
    "        data_test,\n",
    "        device=DEVICE,\n",
    "        epochs=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Функция для обучения и оценки модели\n",
    "    :param parametterization: параметры модели и коэффициент скорости обучения\n",
    "    :param model_class: класс модели нейронной сети\n",
    "    :param data_train: данные для обучения\n",
    "    :param data_test: данные для теста\n",
    "    :param device: устройво для основных расчётов\n",
    "    :param epochs: количество эпох обучения\n",
    "    :return: (-1) * F1-score (weighted) \n",
    "\n",
    "             F1-score, т.к. типы отзывов распределены неравномерно, \n",
    "             (~60 % имеют положительную маркекровку, ~20 % - нейтральная и ~20 % негативных)\n",
    "             и простая метрика как Точность будет менее информативна.\n",
    "\n",
    "             Weighted, т.к. задача классификации имеет более чем 2 класса.\n",
    "\n",
    "             Домножение на (-1) необходимо, так как нас интересует максимизация F1-score,\n",
    "             а функция fmin может только минимизировать, вот и переворачиваем. \n",
    "    \"\"\"\n",
    "    # получение коэффициента скорости обучения\n",
    "    lr = parametterization.pop('lr')\n",
    "    \n",
    "    # создание объекта модели нейронной сети\n",
    "    model = model_class(**parametterization)\n",
    "    model.to(device)\n",
    "\n",
    "    # установка функции ошибки и оптимизатора\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # этап обучения модели\n",
    "    for _ in range(epochs):\n",
    "        for x, y in data_train:\n",
    "\n",
    "            model.train()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # этап оценки модели\n",
    "    model.eval()\n",
    "\n",
    "    # список всех оценок для каждого батча\n",
    "    f1_score_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for x, y in data_test:\n",
    "            x = x.to(device)\n",
    "            \n",
    "            f1_score_list.append(\n",
    "                f1_score(\n",
    "                    y_true=y.numpy(),\n",
    "                    y_pred=model(x).argmax(axis=1).cpu().numpy(),\n",
    "                    average='weighted'\n",
    "                )\n",
    "            )\n",
    "        \n",
    "    f1_score_list = np.array(f1_score_list)\n",
    "    \n",
    "    # освобождение памяти от модели\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # среднее значение по всем оценкам батчей\n",
    "    return (-1) * f1_score_list.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_of_hyperparameters(\n",
    "        search_parameters,\n",
    "        model_class,\n",
    "        data_train,\n",
    "        data_test,\n",
    "        number_of_try=100,\n",
    "        epochs=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Функция поиска гиперпараметров\n",
    "    :param search_parameters: \n",
    "    :param model_class: класс модели нейронной сети\n",
    "    :param data_train: данные для обучения\n",
    "    :param data_test: данные для теста\n",
    "    :param number_of_try: число итерация для алогоритма поиска\n",
    "    :param epochs: число эпох для обучения одной сети\n",
    "    :return: словарь содержащий найденные наилучшие гиперпараметры\n",
    "    \"\"\"\n",
    "    best_hyperparameters = fmin(\n",
    "        fn=partial(\n",
    "            train_evaluate,\n",
    "            model_class=model_class, \n",
    "            data_train=data_train,\n",
    "            data_test=data_test,\n",
    "            device=DEVICE,\n",
    "            epochs=epochs\n",
    "        ),\n",
    "        space=search_parameters,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=number_of_try\n",
    "    )\n",
    "    \n",
    "    print(space_eval(search_parameters, best_hyperparameters))\n",
    "\n",
    "    return space_eval(search_parameters, best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# словарь для хранения наилучших гиперпараметров\n",
    "best_hyperparameters = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор гиперпараметров для CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# область поиска гиперпараметров для CNN сети\n",
    "cnn_parameters = {\n",
    "    'lr': hp.uniform('lr', 1e-3, 1e-1),\n",
    "    'number_of_filters': hp.choice('number_of_filters', range(10, 101, 5)),\n",
    "    'vector_size': VECTOR_SIZE\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:28:40<00:00, 53.20s/trial, best loss: -0.7177714674018713]\n",
      "{'lr': 0.0019840863354355755, 'number_of_filters': 70, 'vector_size': 100}\n"
     ]
    }
   ],
   "source": [
    "# w2v CNN\n",
    "best_hyperparameters['w2v_CNN'] = search_of_hyperparameters(\n",
    "    search_parameters=cnn_parameters,\n",
    "    model_class=CNN,\n",
    "    data_train=w2v_data_train,\n",
    "    data_test=w2v_data_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:53:01<00:00, 67.81s/trial, best loss: -0.7167403494849508]\n",
      "{'lr': 0.005238807869458511, 'number_of_filters': 75, 'vector_size': 100}\n"
     ]
    }
   ],
   "source": [
    "# fasttesxt CNN\n",
    "best_hyperparameters['fasttext_CNN'] = search_of_hyperparameters(\n",
    "    search_parameters=cnn_parameters,\n",
    "    model_class=CNN,\n",
    "    data_train=fasttext_data_train,\n",
    "    data_test=fasttext_data_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор гиперпараметров для LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# область поиска гиперпараметров для LSTM сети\n",
    "lstm_parameters = {\n",
    "    'lr': hp.uniform('lr', 1e-3, 1e-1),\n",
    "    'vector_size': VECTOR_SIZE,\n",
    "    'lstm_out_features': hp.choice('lstm_out_features', range(25, int(VECTOR_SIZE * 0.6) + 1, 5))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:26:45<00:00, 52.05s/trial, best loss: -0.6984205988593378]\n",
      "{'lr': 0.013538336892539438, 'lstm_out_features': 50, 'vector_size': 100}\n"
     ]
    }
   ],
   "source": [
    "# w2v LSTM\n",
    "best_hyperparameters['w2v_LSTM'] = search_of_hyperparameters(\n",
    "    search_parameters=lstm_parameters,\n",
    "    model_class=LSTM,\n",
    "    data_train=w2v_data_train,\n",
    "    data_test=w2v_data_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:52:41<00:00, 67.61s/trial, best loss: -0.6760539322157916]\n",
      "{'lr': 0.016816389472063677, 'lstm_out_features': 45, 'vector_size': 100}\n"
     ]
    }
   ],
   "source": [
    "# fasttesxt LSTM\n",
    "best_hyperparameters['fasttext_LSTM'] = search_of_hyperparameters(\n",
    "    search_parameters=lstm_parameters,\n",
    "    model_class=LSTM,\n",
    "    data_train=fasttext_data_train,\n",
    "    data_test=fasttext_data_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор гиперпараметров для LSTM_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# область поиска гиперпараметров для LSTM_CNN сети\n",
    "lstm_cnn_parameters = {\n",
    "    'lr': hp.uniform('lr', 1e-3, 1e-1),\n",
    "    'vector_size': VECTOR_SIZE,\n",
    "    'lstm_out': hp.choice('lstm_out', range(25, int(VECTOR_SIZE * 0.6) + 1, 5)),\n",
    "    'number_of_filters': hp.choice('number_of_filters', range(10, 101, 5))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:27:01<00:00, 52.21s/trial, best loss: -0.7161151110128887]\n",
      "{'lr': 0.0010517228365822806, 'lstm_out': 55, 'number_of_filters': 80, 'vector_size': 100}\n"
     ]
    }
   ],
   "source": [
    "# w2v LSTM_CNN\n",
    "best_hyperparameters['w2v_LSTM_CNN'] = search_of_hyperparameters(\n",
    "    search_parameters=lstm_cnn_parameters,\n",
    "    model_class=LSTM_CNN,\n",
    "    data_train=w2v_data_train,\n",
    "    data_test=w2v_data_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:52:05<00:00, 67.25s/trial, best loss: -0.705023389704645]\n",
      "{'lr': 0.003091052673013807, 'lstm_out': 30, 'number_of_filters': 20, 'vector_size': 100}\n"
     ]
    }
   ],
   "source": [
    "# fasttesxt LSTM_CNN\n",
    "best_hyperparameters['fasttext_LSTM_CNN'] = search_of_hyperparameters(\n",
    "    search_parameters=lstm_cnn_parameters,\n",
    "    model_class=LSTM_CNN,\n",
    "    data_train=fasttext_data_train,\n",
    "    data_test=fasttext_data_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запись Гиперпараметров в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/best_hyperparameters.pkl', 'wb') as f:\n",
    "    pickle.dump(best_hyperparameters, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Былы получены наиболее успешные гиперпараметры для 6 моделей: CNN, LSTM, LSTM_CNN обученных на Word2Vec и FastText текстах каждая."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
